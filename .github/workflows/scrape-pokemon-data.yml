name: Scrape Pokemon Go Data

on:
  schedule:
    # Run every hour at minute 0
    - cron: '0 * * * *'
  workflow_dispatch:
    # Allow manual triggering
    inputs:
      force_scrape:
        description: 'Force scrape even with cached data'
        required: false
        default: 'false'
        type: boolean

jobs:
  scrape:
    name: Scrape Pokemon Go Data
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install httpx beautifulsoup4 requests lxml brotli

      - name: Run Pokemon Go scraper
        run: |
          mkdir -p data
          python pogo_scraper/scraper.py --all --output-dir data --cache-duration 0
        env:
          PYTHONPATH: ${{ github.workspace }}

      - name: Validate scraping succeeded
        run: |
          echo "Validating that scraping was successful..."

          # Check if data files exist
          if [ ! -f data/events.json ] || [ ! -f data/raids.json ] || [ ! -f data/research.json ] || [ ! -f data/eggs.json ]; then
            echo "âŒ ERROR: One or more data files were not created"
            echo "This indicates a critical failure in the scraping process"
            exit 1
          fi

          # Count total items across all files
          TOTAL_ITEMS=0
          for file in data/events.json data/raids.json data/research.json data/eggs.json data/rocket-lineups.json data/promo-codes.json; do
            if [ -f "$file" ]; then
              COUNT=$(python -c "import sys, json; data=json.load(open('$file')); print(len(data) if isinstance(data, list) else 0)")
              TOTAL_ITEMS=$((TOTAL_ITEMS + COUNT))
              echo "  $file: $COUNT items"
            fi
          done

          echo "Total items scraped: $TOTAL_ITEMS"

          # Fail if no data was scraped (indicates LeekDuck is down or blocking requests)
          if [ $TOTAL_ITEMS -eq 0 ]; then
            echo ""
            echo "âŒ ERROR: Scraping failed - no data was retrieved from any source"
            echo "This typically indicates that:"
            echo "  - LeekDuck.com is down or returning errors (500, 503, etc.)"
            echo "  - LeekDuck.com is blocking our requests"
            echo "  - Network connectivity issues"
            echo ""
            echo "Please check the scraper logs above for HTTP error details"
            exit 1
          fi

          echo "âœ… Validation passed: Successfully scraped $TOTAL_ITEMS items"

      - name: Verify scraped data
        run: |
          echo "Checking scraped data files..."
          ls -la data/
          echo "Events count: $(cat data/events.json | python -c "import sys, json; print(len(json.load(sys.stdin)))")" || echo "events.json not found"
          echo "Raids count: $(cat data/raids.json | python -c "import sys, json; print(len(json.load(sys.stdin)))")" || echo "raids.json not found"
          echo "Research count: $(cat data/research.json | python -c "import sys, json; print(len(json.load(sys.stdin)))")" || echo "research.json not found"
          echo "Eggs count: $(cat data/eggs.json | python -c "import sys, json; print(len(json.load(sys.stdin)))")" || echo "eggs.json not found"

      - name: Clean up for data branch
        run: |
          # Move data files to temp location
          mv data ../temp_data

          # Clean repository (keep .git)
          find . -mindepth 1 -maxdepth 1 ! -name '.git' -exec rm -rf {} +

          # Move data files back
          mv ../temp_data/* .

          # Clean up temp directory
          rmdir ../temp_data

      - name: Configure Git
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      - name: Create/Update data branch
        run: |
          # Create orphan branch (or switch to existing data branch)
          git checkout --orphan data || git checkout data

          # Add all data files
          git add --all

          # Check if there are changes to commit
          if git diff --cached --quiet; then
            echo "No changes to commit"
            exit 0
          fi

          # Generate statistics for commit message body
          STATS_BODY=""

          # Count items in each data file
          if [ -f events.json ]; then
            EVENTS_COUNT=$(python3 -c "import json; print(len(json.load(open('events.json'))))" 2>/dev/null || echo "0")
            if [ "$EVENTS_COUNT" != "0" ]; then
              STATS_BODY="${STATS_BODY}- ${EVENTS_COUNT} events\n"
            fi
          fi

          if [ -f raids.json ]; then
            RAIDS_COUNT=$(python3 -c "import json; print(len(json.load(open('raids.json'))))" 2>/dev/null || echo "0")
            if [ "$RAIDS_COUNT" != "0" ]; then
              STATS_BODY="${STATS_BODY}- ${RAIDS_COUNT} raids\n"
            fi
          fi

          if [ -f research.json ]; then
            RESEARCH_COUNT=$(python3 -c "import json; print(len(json.load(open('research.json'))))" 2>/dev/null || echo "0")
            if [ "$RESEARCH_COUNT" != "0" ]; then
              STATS_BODY="${STATS_BODY}- ${RESEARCH_COUNT} research\n"
            fi
          fi

          if [ -f eggs.json ]; then
            EGGS_COUNT=$(python3 -c "import json; print(len(json.load(open('eggs.json'))))" 2>/dev/null || echo "0")
            if [ "$EGGS_COUNT" != "0" ]; then
              STATS_BODY="${STATS_BODY}- ${EGGS_COUNT} eggs\n"
            fi
          fi

          if [ -f rocket-lineups.json ]; then
            ROCKET_COUNT=$(python3 -c "import json; print(len(json.load(open('rocket-lineups.json'))))" 2>/dev/null || echo "0")
            if [ "$ROCKET_COUNT" != "0" ]; then
              STATS_BODY="${STATS_BODY}- ${ROCKET_COUNT} rocket lineups\n"
            fi
          fi

          if [ -f promo-codes.json ]; then
            PROMO_COUNT=$(python3 -c "import json; print(len(json.load(open('promo-codes.json'))))" 2>/dev/null || echo "0")
            if [ "$PROMO_COUNT" != "0" ]; then
              STATS_BODY="${STATS_BODY}- ${PROMO_COUNT} promo codes\n"
            fi
          fi

          # Create commit with timestamp as subject and stats as body
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          printf -v COMMIT_MSG "Update Pokemon Go data - %s\n\n%b" "$TIMESTAMP" "$STATS_BODY"
          git commit -m "$COMMIT_MSG"

      - name: Push to data branch
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: data
          force: true

      - name: Create release summary
        if: success()
        run: |
          echo "## Pokemon Go Data Updated ðŸŽ‰" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Successfully scraped and updated Pokemon Go data at $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Data Files Updated:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… events.json" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… raids.json" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… research.json" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… eggs.json" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Access Data:" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** \`data\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Raw Files:** \`https://raw.githubusercontent.com/${{ github.repository }}/data/[filename].json\`" >> $GITHUB_STEP_SUMMARY